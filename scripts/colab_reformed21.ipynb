{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "!pip install yt-dlp youtube-transcript-api"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Upload reformed21_transcripts.json (if you have one from a previous run)\n",
                "# before running the next cell. If this is your first run, skip this step.\n",
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "if not os.path.exists('reformed21_transcripts.json'):\n",
                "    print('No previous file found. Upload reformed21_transcripts.json if you have one, or skip to the next cell.')\n",
                "    try:\n",
                "        uploaded = files.upload()\n",
                "        print(f'Uploaded: {list(uploaded.keys())}')\n",
                "    except Exception:\n",
                "        print('No file uploaded. Starting fresh.')\n",
                "else:\n",
                "    print('Previous file already exists. Skipping upload.')"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import json\n",
                "import os\n",
                "import http.cookiejar\n",
                "import requests as req_lib\n",
                "import yt_dlp\n",
                "from youtube_transcript_api import YouTubeTranscriptApi\n",
                "\n",
                "CHANNEL_URL = \"https://www.youtube.com/@Reformed21TV/videos\"\n",
                "OUTPUT_FILE = \"reformed21_transcripts.json\"\n",
                "COOKIES_FILE = \"cookies.txt\"\n",
                "\n",
                "SKIP_KEYWORDS = [\"sermon clips\", \"sermon clip\", \"thoughts from his servants\", \"cuplikan\", \"highlight\"]\n",
                "\n",
                "def should_skip(title):\n",
                "    return any(kw in title.lower() for kw in SKIP_KEYWORDS)\n",
                "\n",
                "def build_cookie_session():\n",
                "    \"\"\"Load a Netscape cookies.txt into a requests.Session if the file exists.\"\"\"\n",
                "    if not os.path.exists(COOKIES_FILE):\n",
                "        return None\n",
                "    try:\n",
                "        jar = http.cookiejar.MozillaCookieJar(COOKIES_FILE)\n",
                "        jar.load(ignore_discard=True, ignore_expires=True)\n",
                "        session = req_lib.Session()\n",
                "        session.cookies = jar\n",
                "        print(f\"\ud83c\udf6a Loaded YouTube cookies from {COOKIES_FILE}\")\n",
                "        return session\n",
                "    except Exception as e:\n",
                "        print(f\"\u26a0\ufe0f Failed to load cookies: {e}\")\n",
                "        return None\n",
                "\n",
                "def main():\n",
                "    # Step 0: Load existing results\n",
                "    results = []\n",
                "    no_transcript_ids = set()\n",
                "\n",
                "    if os.path.exists(OUTPUT_FILE):\n",
                "        with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
                "            data = json.load(f)\n",
                "            results = data.get(\"transcripts\", [])\n",
                "            no_transcript_ids = set(data.get(\"no_transcript_ids\", []))\n",
                "        print(f\"\ud83d\udcc2 Loaded {len(results)} extracted + {len(no_transcript_ids)} permanently skipped (no transcript).\\n\")\n",
                "\n",
                "    done_ids = {r[\"video_id\"] for r in results}\n",
                "\n",
                "    # Step 1: Get all videos\n",
                "    print(\"Fetching channel video list...\")\n",
                "    ydl_opts = {\"extract_flat\": \"in_playlist\", \"quiet\": True, \"no_warnings\": True}\n",
                "    if os.path.exists(COOKIES_FILE):\n",
                "        ydl_opts[\"cookiefile\"] = COOKIES_FILE\n",
                "        \n",
                "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
                "        info = ydl.extract_info(CHANNEL_URL, download=False)\n",
                "        all_videos = [v for v in info.get(\"entries\", []) if not should_skip(v.get(\"title\", \"\"))]\n",
                "\n",
                "    remaining = [v for v in all_videos if v[\"id\"] not in done_ids and v[\"id\"] not in no_transcript_ids]\n",
                "    print(f\"Total eligible: {len(all_videos)} | Done: {len(done_ids)} | No transcript: {len(no_transcript_ids)} | To process: {len(remaining)}\\n\")\n",
                "\n",
                "    if not remaining:\n",
                "        print(\"\ud83c\udf89 Nothing left to process!\")\n",
                "        return\n",
                "\n",
                "    # Step 2: Fetch transcripts\n",
                "    cookie_session = build_cookie_session()\n",
                "    ytt = YouTubeTranscriptApi(http_client=cookie_session) if cookie_session else YouTubeTranscriptApi()\n",
                "    \n",
                "    new_count = 0\n",
                "    no_transcript_count = 0\n",
                "    ip_blocked_count = 0\n",
                "    consecutive_ip_errors = 0\n",
                "    MAX_CONSECUTIVE_ERRORS = 3\n",
                "\n",
                "    for i, video in enumerate(remaining):\n",
                "        vid = video[\"id\"]\n",
                "        title = video.get(\"title\", \"Unknown\")\n",
                "        url = video.get(\"url\", f\"https://www.youtube.com/watch?v={vid}\")\n",
                "\n",
                "        print(f\"[{i+1}/{len(remaining)}] {title}...\", end=\" \")\n",
                "\n",
                "        import time\n",
                "        from youtube_transcript_api._errors import NoTranscriptFound, TranscriptsDisabled, VideoUnavailable\n",
                "        \n",
                "        try:\n",
                "            try:\n",
                "                transcript = ytt.fetch(vid, languages=[\"id\"])\n",
                "                detected_lang = \"id\"\n",
                "            except NoTranscriptFound:\n",
                "                try:\n",
                "                    transcript = ytt.fetch(vid, languages=[\"en\"])\n",
                "                    detected_lang = \"en\"\n",
                "                except NoTranscriptFound:\n",
                "                    transcript_list = ytt.list(vid)\n",
                "                    available = list(transcript_list)\n",
                "                    if not available:\n",
                "                        raise NoTranscriptFound(vid, [], None)\n",
                "                    transcript = ytt.fetch(vid, languages=[available[0].language_code])\n",
                "                    detected_lang = available[0].language_code\n",
                "\n",
                "            segments = [{\"text\": s[\"text\"], \"start\": s[\"start\"], \"duration\": s[\"duration\"]} for s in transcript]\n",
                "            full_text = \" \".join([s[\"text\"].strip() for s in transcript])\n",
                "\n",
                "            results.append({\n",
                "                \"video_id\": vid,\n",
                "                \"title\": title,\n",
                "                \"source_url\": url,\n",
                "                \"full_text\": full_text.replace(\"\\n\", \" \"),\n",
                "                \"segments\": segments,\n",
                "                \"language\": detected_lang\n",
                "            })\n",
                "            new_count += 1\n",
                "            consecutive_ip_errors = 0\n",
                "            print(f\"\u2705 OK ({len(segments)} segments)\")\n",
                "        except Exception as e:\n",
                "            err = str(e).lower()\n",
                "\n",
                "            if \"blocked\" in err or \"ip\" in err or \"too many\" in err:\n",
                "                ip_blocked_count += 1\n",
                "                consecutive_ip_errors += 1\n",
                "                print(f\"\ud83d\udeab IP BLOCKED (will retry next run)\")\n",
                "                if consecutive_ip_errors >= MAX_CONSECUTIVE_ERRORS:\n",
                "                    print(f\"\\n\u26d4 IP BLOCKED {MAX_CONSECUTIVE_ERRORS}x in a row! Stopping early.\")\n",
                "                    break\n",
                "            else:\n",
                "                no_transcript_ids.add(vid)\n",
                "                no_transcript_count += 1\n",
                "                consecutive_ip_errors = 0\n",
                "                print(f\"\u26a0\ufe0f NO TRANSCRIPT ({str(e)[:50]})\")\n",
                "\n",
                "        time.sleep(3)\n",
                "\n",
                "    # Step 3: Save everything\n",
                "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
                "        json.dump({\n",
                "            \"transcripts\": results,\n",
                "            \"no_transcript_ids\": list(no_transcript_ids)\n",
                "        }, f, ensure_ascii=False, indent=2)\n",
                "\n",
                "    # Step 4: Stats\n",
                "    total_done = len(results)\n",
                "    total_no_transcript = len(no_transcript_ids)\n",
                "    still_remaining = len(all_videos) - total_done - total_no_transcript\n",
                "\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"\ud83d\udcca STATS\")\n",
                "    print(f\"{'='*50}\")\n",
                "    print(f\"  \u2705 Previously extracted:     {len(done_ids)}\")\n",
                "    print(f\"  \u2705 Newly extracted:          {new_count}\")\n",
                "    print(f\"  \u26a0\ufe0f No transcript (permanent): {total_no_transcript}\")\n",
                "    print(f\"  \ud83d\udeab IP blocked (will retry):  {ip_blocked_count}\")\n",
                "    print(f\"  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\")\n",
                "    print(f\"  \ud83d\udce6 Total saved:              {total_done}\")\n",
                "    print(f\"  \u23f3 Still remaining:           {still_remaining}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    if still_remaining > 0:\n",
                "        print(f\"\u23f3 Re-run this script later to continue ({still_remaining} videos left).\")\n",
                "    else:\n",
                "        print(f\"\ud83c\udf89 All done! Every eligible video has been extracted.\")\n",
                "    print(f\"\\nDownload '{OUTPUT_FILE}' from the Colab file browser.\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()\n",
                ""
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Download the result file\n",
                "from google.colab import files\n",
                "files.download('reformed21_transcripts.json')"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}