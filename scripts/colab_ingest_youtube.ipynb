{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# YouTube Sermon Ingestion\n",
                "\n",
                "This notebook ingests YouTube sermons into the **production database** via the API.\n",
                "\n",
                "### Steps:\n",
                "1. Run Cell 1 to install dependencies\n",
                "2. Run Cell 2 to upload cookies.txt (optional, prevents YouTube IP blocks)\n",
                "3. Run Cell 3 to start ingestion (API key is pre-configured)\n",
                "\n",
                "The INGEST_API_KEY never expires, so you can re-run this notebook anytime."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q yt-dlp requests"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# (Optional) Upload cookies.txt to prevent YouTube IP blocks\n",
                "import os\n",
                "if not os.path.exists('cookies.txt'):\n",
                "    print('Upload cookies.txt if you have one (optional).')\n",
                "    try:\n",
                "        from google.colab import files\n",
                "        uploaded = files.upload()\n",
                "        print(f'Uploaded: {list(uploaded.keys())}')\n",
                "    except Exception:\n",
                "        print('No file uploaded. Continuing without cookies.')\n",
                "else:\n",
                "    print('cookies.txt already exists.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import time\n",
                "import requests\n",
                "import yt_dlp\n",
                "\n",
                "# ============================================================\n",
                "# CONFIGURATION \u2014 edit these before running\n",
                "# ============================================================\n",
                "\n",
                "# Your production API base URL (no trailing slash)\n",
                "API_BASE_URL = \"https://sermon-rag-production.up.railway.app\"\n",
                "\n",
                "# Static API key for ingestion (never expires, set in Railway env vars)\n",
                "INGEST_API_KEY = \"ThqQrkLiWe_yYFwLJRv3q4OEGnawggI-5iU9Bgugtsc\"\n",
                "\n",
                "# YouTube channel to ingest\n",
                "CHANNEL_URL = \"https://www.youtube.com/@Reformed21TV/videos\"\n",
                "\n",
                "# Titles containing these keywords will be skipped\n",
                "SKIP_KEYWORDS = [\n",
                "    \"Sermon Clips\", \"Sermon Clip\", \"Koor \", \"Virtual Ensemble\",\n",
                "    \"Virtual Choir\", \"Sekolah Minggu\", \"Jendela Anak\", \"Perkenalan\",\n",
                "    \"Thoughts from His Servants\", \"Cuplikan\", \"Highlight\",\n",
                "]\n",
                "\n",
                "# How many URLs to send per API call\n",
                "BATCH_SIZE = 3\n",
                "\n",
                "# Seconds to wait between batches (to avoid YouTube rate limits)\n",
                "BATCH_DELAY = 10\n",
                "\n",
                "# Preferred transcript language\n",
                "LANGUAGE = \"id\"\n",
                "\n",
                "# Optional cookies file for yt-dlp (to avoid IP blocks)\n",
                "COOKIES_FILE = \"cookies.txt\"\n",
                "\n",
                "# ============================================================\n",
                "\n",
                "\n",
                "def get_full_sermon_urls() -> list[dict]:\n",
                "    \"\"\"Fetch channel videos and filter to full sermons only.\"\"\"\n",
                "    ydl_opts = {\n",
                "        \"quiet\": True,\n",
                "        \"no_warnings\": True,\n",
                "        \"extract_flat\": True,\n",
                "        \"skip_download\": True,\n",
                "    }\n",
                "    if os.path.exists(COOKIES_FILE):\n",
                "        ydl_opts[\"cookiefile\"] = COOKIES_FILE\n",
                "        print(f\"\ud83c\udf6a Using cookies from {COOKIES_FILE}\")\n",
                "\n",
                "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
                "        info = ydl.extract_info(CHANNEL_URL, download=False)\n",
                "        entries = info.get(\"entries\", [])\n",
                "\n",
                "    sermons = []\n",
                "    skipped = []\n",
                "    for e in entries:\n",
                "        title = e.get(\"title\", \"\")\n",
                "        if any(kw.lower() in title.lower() for kw in SKIP_KEYWORDS):\n",
                "            skipped.append(title)\n",
                "            continue\n",
                "        sermons.append({\n",
                "            \"id\": e[\"id\"],\n",
                "            \"title\": title,\n",
                "            \"url\": f\"https://www.youtube.com/watch?v={e['id']}\",\n",
                "        })\n",
                "\n",
                "    print(f\"\ud83d\udcfa Found {len(sermons)} full sermons, skipped {len(skipped)} non-sermon videos.\")\n",
                "    return sermons\n",
                "\n",
                "\n",
                "def ingest_batch(urls: list[str]) -> dict:\n",
                "    \"\"\"Send a batch of YouTube URLs to the production API for ingestion.\"\"\"\n",
                "    resp = requests.post(\n",
                "        f\"{API_BASE_URL}/api/ingest/youtube\",\n",
                "        json={\"urls\": urls, \"language\": LANGUAGE},\n",
                "        headers={\"X-API-Key\": INGEST_API_KEY},\n",
                "        timeout=300,  # 5 min timeout per batch (embedding takes time)\n",
                "    )\n",
                "    resp.raise_for_status()\n",
                "    return resp.json()\n",
                "\n",
                "\n",
                "def main():\n",
                "    if not INGEST_API_KEY:\n",
                "        print(\"\u274c ERROR: You must set INGEST_API_KEY before running this script!\")\n",
                "        return\n",
                "\n",
                "    print(\"=\" * 60)\n",
                "    print(\"\ud83d\ude80 YouTube Sermon Ingestion (via Production API)\")\n",
                "    print(\"=\" * 60)\n",
                "    print(f\"   API:     {API_BASE_URL}\")\n",
                "    print(f\"   Channel: {CHANNEL_URL}\")\n",
                "    print(f\"   Batch:   {BATCH_SIZE} URLs, {BATCH_DELAY}s delay\")\n",
                "    print()\n",
                "\n",
                "    # Step 1: Get video list\n",
                "    sermons = get_full_sermon_urls()\n",
                "    if not sermons:\n",
                "        print(\"Nothing to process!\")\n",
                "        return\n",
                "\n",
                "    # Step 2: Ingest in batches\n",
                "    total_processed = 0\n",
                "    total_chunks = 0\n",
                "    total_errors = []\n",
                "    total_skipped = 0\n",
                "\n",
                "    for i in range(0, len(sermons), BATCH_SIZE):\n",
                "        batch = sermons[i : i + BATCH_SIZE]\n",
                "        batch_urls = [s[\"url\"] for s in batch]\n",
                "        batch_num = (i // BATCH_SIZE) + 1\n",
                "        total_batches = (len(sermons) + BATCH_SIZE - 1) // BATCH_SIZE\n",
                "\n",
                "        print(f\"\\n--- Batch {batch_num}/{total_batches} ---\")\n",
                "        for s in batch:\n",
                "            print(f\"  \ud83d\udcf9 {s['title']}\")\n",
                "\n",
                "        try:\n",
                "            start = time.time()\n",
                "            result = ingest_batch(batch_urls)\n",
                "            elapsed = time.time() - start\n",
                "\n",
                "            processed = result.get(\"sources_processed\", 0)\n",
                "            chunks = result.get(\"chunks_created\", 0)\n",
                "            errors = result.get(\"errors\", [])\n",
                "            skipped = len(batch) - processed - len(errors)\n",
                "\n",
                "            total_processed += processed\n",
                "            total_chunks += chunks\n",
                "            total_errors.extend(errors)\n",
                "            total_skipped += skipped\n",
                "\n",
                "            print(f\"  \u2705 {processed} ingested, {skipped} skipped, \"\n",
                "                  f\"{len(errors)} errors, {elapsed:.1f}s\")\n",
                "            if errors:\n",
                "                for err in errors:\n",
                "                    print(f\"    \u26a0\ufe0f {err}\")\n",
                "\n",
                "        except requests.exceptions.HTTPError as e:\n",
                "            print(f\"  \u274c API Error: {e.response.status_code} \u2014 {e.response.text[:200]}\")\n",
                "            if e.response.status_code == 401:\n",
                "                print(\"     Your INGEST_API_KEY is invalid. Check the key!\")\n",
                "                break\n",
                "            elif e.response.status_code == 403:\n",
                "                print(\"     Your account is not an admin. Contact the system administrator.\")\n",
                "                break\n",
                "            total_errors.append(str(e))\n",
                "        except Exception as e:\n",
                "            print(f\"  \u274c Error: {e}\")\n",
                "            total_errors.append(str(e))\n",
                "\n",
                "        print(f\"  \ud83d\udcca Running total: {total_processed} ingested, \"\n",
                "              f\"{total_skipped} skipped, {total_chunks} chunks\")\n",
                "\n",
                "        # Delay between batches\n",
                "        if i + BATCH_SIZE < len(sermons):\n",
                "            print(f\"  \u23f1\ufe0f Waiting {BATCH_DELAY}s...\")\n",
                "            time.sleep(BATCH_DELAY)\n",
                "\n",
                "    # Final stats\n",
                "    print(f\"\\n{'=' * 60}\")\n",
                "    print(f\"\ud83d\udcca FINAL STATS\")\n",
                "    print(f\"{'=' * 60}\")\n",
                "    print(f\"  \u2705 Ingested:   {total_processed}\")\n",
                "    print(f\"  \u23ed\ufe0f  Skipped:    {total_skipped}\")\n",
                "    print(f\"  \ud83d\udce6 Chunks:     {total_chunks}\")\n",
                "    print(f\"  \u26a0\ufe0f  Errors:     {len(total_errors)}\")\n",
                "    print(f\"{'=' * 60}\")\n",
                "\n",
                "    if total_errors:\n",
                "        print(\"\\nErrors:\")\n",
                "        for err in total_errors:\n",
                "            print(f\"  - {err}\")\n",
                "\n",
                "    print(\"\\n\ud83c\udf89 Done!\")\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()\n",
                ""
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}