{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# GRII YouTube Transcript Extractor\n", "\n", "Extracts transcripts in batches. Re-run with a fresh runtime if you get IP blocked.\n", "Upload your previous `grii_transcripts.json` to resume where you left off."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["!pip install -q youtube-transcript-api yt-dlp"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json, os, time\n",
    "import yt_dlp\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound, VideoUnavailable, IpBlocked\n",
    "\n",
    "# Load previous results if uploaded\n",
    "existing_ids = set()\n",
    "prev_results = []\n",
    "prev_errors = []\n",
    "if os.path.exists('grii_transcripts.json'):\n",
    "    with open('grii_transcripts.json') as f:\n",
    "        prev = json.load(f)\n",
    "    prev_results = prev.get('transcripts', [])\n",
    "    prev_errors = prev.get('errors', [])\n",
    "    existing_ids = {t['video_id'] for t in prev_results}\n",
    "    print(f'Loaded {len(prev_results)} previous transcripts, will skip those.')\n",
    "else:\n",
    "    print('No previous file found, starting fresh.')\n",
    "\n",
    "# Fetch channel video list\n",
    "print('Fetching channel videos...')\n",
    "ydl_opts = {'quiet': True, 'no_warnings': True, 'extract_flat': True, 'skip_download': True}\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info('https://www.youtube.com/@GRIIPusatSore/videos', download=False)\n",
    "    entries = info.get('entries', [])\n",
    "\n",
    "SKIP_KEYWORDS = ['Sermon Clips', 'Sermon Clip', 'Koor ', 'Virtual Ensemble',\n",
    "                 'Virtual Choir', 'Sekolah Minggu', 'Jendela Anak', 'Perkenalan']\n",
    "sermons = []\n",
    "for e in entries:\n",
    "    title = e.get('title', '')\n",
    "    if not any(kw.lower() in title.lower() for kw in SKIP_KEYWORDS):\n",
    "        sermons.append({'id': e['id'], 'title': title})\n",
    "\n",
    "remaining = [s for s in sermons if s['id'] not in existing_ids]\n",
    "print(f'Total: {len(sermons)} sermons, {len(existing_ids)} already done, {len(remaining)} remaining')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract transcripts with delays to avoid IP ban\n",
    "results = list(prev_results)\n",
    "errors = list(prev_errors)\n",
    "ytt = YouTubeTranscriptApi()\n",
    "ip_blocked = False\n",
    "\n",
    "for i, sermon in enumerate(remaining):\n",
    "    vid = sermon['id']\n",
    "    title = sermon['title']\n",
    "    print(f'[{i+1}/{len(remaining)}] {title}...', end=' ')\n",
    "\n",
    "    try:\n",
    "        detected_lang = 'id'\n",
    "        try:\n",
    "            transcript = ytt.fetch(vid, languages=['id'])\n",
    "        except NoTranscriptFound:\n",
    "            try:\n",
    "                transcript = ytt.fetch(vid, languages=['en'])\n",
    "                detected_lang = 'en'\n",
    "            except NoTranscriptFound:\n",
    "                tlist = ytt.list(vid)\n",
    "                available = list(tlist)\n",
    "                if not available:\n",
    "                    raise NoTranscriptFound(vid, [], None)\n",
    "                transcript = ytt.fetch(vid, languages=[available[0].language_code])\n",
    "                detected_lang = available[0].language_code\n",
    "\n",
    "        segments = [{'text': s.text, 'start': s.start, 'duration': s.duration} for s in transcript.snippets]\n",
    "        full_text = ' '.join(s['text'] for s in segments)\n",
    "\n",
    "        try:\n",
    "            with yt_dlp.YoutubeDL({'quiet': True, 'skip_download': True}) as ydl:\n",
    "                meta = ydl.extract_info(f'https://www.youtube.com/watch?v={vid}', download=False)\n",
    "                yt_title = meta.get('title', title)\n",
    "        except Exception:\n",
    "            yt_title = title\n",
    "\n",
    "        results.append({\n",
    "            'video_id': vid, 'title': yt_title, 'full_text': full_text,\n",
    "            'segments': segments, 'language': detected_lang,\n",
    "            'source_url': f'https://www.youtube.com/watch?v={vid}',\n",
    "        })\n",
    "        print(f'OK ({len(segments)} segments)')\n",
    "\n",
    "    except IpBlocked:\n",
    "        print('IP BLOCKED - stopping.')\n",
    "        ip_blocked = True\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append(f'{vid} ({title}): {type(e).__name__}: {str(e)[:100]}')\n",
    "        print(f'FAILED: {type(e).__name__}')\n",
    "\n",
    "    # Delay: 3s per video, extra 10s every 5 videos\n",
    "    time.sleep(3)\n",
    "    if (i + 1) % 5 == 0:\n",
    "        time.sleep(10)\n",
    "\n",
    "new_count = len(results) - len(prev_results)\n",
    "print(f'\\nExtracted {new_count} new transcripts this run. Total: {len(results)}')\n",
    "if ip_blocked:\n",
    "    print('\\n>>> IP was blocked. Save the file, disconnect runtime, reconnect, upload file, and re-run. <<<')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save results\n",
    "import os\n",
    "output = {'transcripts': results, 'errors': errors}\n",
    "with open('grii_transcripts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "total = len(sermons)\n",
    "done = len(results)\n",
    "print(f'Saved {done}/{total} transcripts to grii_transcripts.json')\n",
    "print(f'File size: {os.path.getsize(\"grii_transcripts.json\") / 1024 / 1024:.1f} MB')\n",
    "if done < total:\n",
    "    print(f'\\n{total - done} remaining. Disconnect runtime, reconnect, upload this file, and re-run.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Download the file\n",
    "from google.colab import files\n",
    "files.download('grii_transcripts.json')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
